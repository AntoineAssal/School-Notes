# Memory Management

Operating systems need a mechanism to allocate, remove and protect memory for all its processes. As we know, a program is stored on the disk as a binary executable file and it needs to be brought on the main memory (RAM) by the CPU.
Depending on the memory management in use, the process may be moved between disk and memory during its execution.

Terms| Description|
------------ | ------------
`Segment`| A contiguous chunk of memory assigned to a process.
`Physical Address`, `real address` , `binary address`| An actual memory address that is used to access a specific storage cell in main memory.
`Virtual Address` | A memory address that is relative to the start of a process' address space.
`Relocatable code`|
`Address space`| A range of valid addresses in memory that are available for a program or process (virtual or physical)
`Compaction`| Shifting processes so they are contiguous and all free memory is in one block.
`Internal fragmentation`| Holes of empty/unused space in memory within a partition.
`External fragmentation`| Holes of empty/unused space in memory between allocated partitions.
## Steps for a process

<p align="center">
	<img src="https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter8/8_03_MultistepProcessing.jpg" alt="Steps">
</p>

# Address Binding
The process of mapping the programs logical or virtual address to the physical or main memory addresses. Memory addresses are not absolute and can change depending on the state of the program. Binding can happen at compile time, load time, and execution time. 

- Most systems allow a process to reside in any part of the physical memory. (P.S Adress space starting at 00000 doesn't mean that first address of a user process is 00000)
- Depending on the memory management in use, the process may be moved between disk and memory during its execution.

## Static binding
It happens before run time and remains unchanged during the execution of the program: It is known where processes will reside in memory. (it is dynamic if it happens during execution). The earlier the binding time, the better the execution.
## Binding with the loader
The loader binds addresses from process address space to main memory. The loader binds relocatable addresses (the address to be changed to the actual address) to absolute address (actual address). 

# Generating Addresses
There are several techniques that can be used to determine how addresses are generated for use by a program depending on their state.

## Compile Time:
- The compiler generates the exact physical location in memory starting from some fixed starting position `K`. 
- The OS is not involved here. 
- If at some time, the starting location changes, the code needs to be recompiled
  
<table><tr><td>This is very restrictive because the compiler must know ahead of time how all memory in the system is going to be allocated in order to prevent using an address that might be used by another application.</td></tr></table>

## Load Time:
- The compiler generates an address, but at load time the OS determines the processâ€™ starting position. 
- Once the process loads, it does not move in memory and has its "absolute address". 
  
<table><tr><td>This allows for greater flexibility, but still restricts the process location once it has been started.</td></tr></table>

## Execution Time:
Compiler generates an address, but the OS can place it anywhere in memory. This is the most flexible technique because the OS can remap how the compiled addresses relate to physical memory
addresses on the fly.




# Logical and Physical Adress Spaces
- Logical Address : An address generated by the CPU.
- Physical Address : An adress seen by the memory unit. The address that is loaded into the memory-address register in RAM.
- Both compile-time and load-time address binding generate identical logical and physical addresses.
- In the case of execution time address binding, logical and physical addresses are different. We refer to logical address here as virtual address. The mapping from virtual to physical addresses is done by a hardware device called the Memory-Management Unit(MMU)
- Logical Address Space : The set of all logical addresses generated by a program.
- Physical Address Space : The set of all physical addresses corresponding to these logical addresses.


## Fixed Partitioning
You divide the whole available RAM is divided into fixed sized. Then 3 things can happen:
- Process size <= partition size: The process can be loaded into the given partition.
- Process size > partition size : The process must be allocated several partitions.
- if all partitions are full then the OS swaps out a process from a partition.

<p align="center">
	<img src="https://i.imgur.com/7OpuB7X.png" width="225" alt="Fixed partitioning equal">
</p>
This example uses fixed partitioning with equal sizes.

- Main memory use is efficient.
  - Internal Fragmentation : Unused space within the partition.
  
<p align="center">
	<img src="https://i.imgur.com/7j3IzH7.png" width="225" alt="Fixed partitioning unequal">
</p>

This example uses fixed partitioning with equal sizes which lessens the problem with equal size partitions.

## Equal-size Partitioning Algorithm

All partitions are of equal size so it does not matter which partition is used, we don't have any algos.

<table><tr><td>How to satisfy a request of size N from a list of free partitions in main memory?</td></tr></table>

<table><tr><td><b>PRO</b> : Very simple to implement and fast context switch</td></tr></table>
<table><tr><td><b>CON</b> : Internal fragmentation happens when a free block not used by process A, cannot be used by any other process. </td></tr></table>

## Unequal-size Partitioning Algorithm
- `First Fit algorithm` : Processes can be allocated the first available partition. 
- `Next Fit algorithm` : Processes can be allocated the next available partition.
- `Best Fit algorithm`:  Each process can be allocated the smallest partition withing which it will fit.

## Dynamic Partitioning
- Partitions are of variable length and number
- A process is allocated exactly the required amount of memory.
- So we create partitions based on the process' size when it arrives.

<p align="center">
	<img src="https://i.imgur.com/DL1vZ5P.png" width="450" alt="Dynamic 1">
    <img src="https://i.imgur.com/LcPw1bv.png" width="450" alt="Dynamic 2">
</p>

# Strategies
How do we choose with partition to load the process into. Consider this example to demonstrate the 3 different strategies mentioned. 
Suppose a process requests 12KB of memory and the memory manager currently has a list of unallocated blocks of 6KB, 14KB, 19KB, 11KB, and 13KB blocks. 
<p align="center">
	<img src="https://i.imgur.com/CQZiGOU.png" alt="Memory 1">
</p>

## Best fit
The `best fit` deals with allocating the smallest free partition which meets the requirement of the requesting process. This algorithm first searches the entire list of free partitions and considers the smallest partition that is adequate. It then tries to find a hole which is close to actual process size needed. 
- Tends to leave very large holes and very small holes. 3
- It is slower and tends to fill up memory with tiny useless holes. 
<p align="center">
	<img src="https://i.imgur.com/2MepFAr.png" alt="Best fit">
</p>
  
## Worst fit
The worst fit approach is to locate largest available free portion so that the portion left will be big enough to be useful. It is the reverse of best fit. 
- Worst fit is worst in terms of storage utilization 
 
<p align="center">
	<img src="https://i.imgur.com/J9Qec6U.png" alt="Worst fit">
</p>

## First fit
The first fit approach is to allocate the first free partition or hole large enough which can accommodate the process. It finishes after finding the first suitable free partition. 
- Tends to leave average size holes 
- Faster than best fit. 
 <p align="center">
	<img src="https://i.imgur.com/QugNd7H.png" alt="First fit">
</p>

# Fragmentation

As processes are loaded and removerd from memory, the free memory space is broken into little pieces which results in fragmentation, left as free spaces.

## External Fragmentation
- It exists when there is enough total memory space to satisfy a request, but the available spaces are not contiguous.
- Storage is fragmented into a large number of small holes.
- This a sever problem. In the worst case we could have a block of free (wasted) memory between every 2 processes.
- If all these pieces were one big block instead, we would be able to use it to run more processes.
- **Solution**: Use compaction.
<p align="center">
	<img src="https://i.imgur.com/hsNgGAX.png" width="400" alt="External fragmentation">
</p>

## Internal Fragmentation
- It exists when memory blocks assigned to a process are bigger than what the process actually needs.
- Some portion of the memory is left ununsed, since we can't load another process in the same block.

<p align="center">
	<img src="https://i.imgur.com/H447iW7.png" width="400" alt="Internal fragmentation">
</p>

- **Solution**: Use best-fit strategy.

## What is Compaction?
- Shuffling the memory contents to place all free memory together in one large block.
- It is used to reduce external fragmentation.
- It essentially groups processes with each other, and external fragments with each other.
### Problems with Compaction?
- Compaction is not always possible.
	- If relocation is static and is done at assembly or load time, compaction cannot be done.
	- Only possible if relocation is dynamoc and done at execution time.
- Any pointers to a block need to be updated when the block is moved
  - Memory address might get corrupted.

